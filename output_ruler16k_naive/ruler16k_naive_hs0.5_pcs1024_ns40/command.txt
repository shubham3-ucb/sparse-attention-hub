OUT="/home/nvidia/shubham/sparse/new_sparse/sparse-attention-hub/output_ruler16k_naive/ruler16k_naive_hs0.5_pcs1024_ns40" MODEL_NAME="meta-llama/Llama-3.1-8B-Instruct" PREFILL_CHUNK_SIZE=1024 EXTEND_CONTEXT=0 ENABLE_POSITION_REASSIGNMENT=0 COMPARE_MASK_ROPED_VS_UNROPED=0 SPARSE_DEBUG=0 MAX_CONTEXT_LENGTH=2147483647 OUTPUT_DIR="/home/nvidia/shubham/sparse/new_sparse/sparse-attention-hub/output_ruler16k_naive/ruler16k_naive_hs0.5_pcs1024_ns40" SPARSE_LOG_PATH="/home/nvidia/shubham/sparse/new_sparse/sparse-attention-hub/output_ruler16k_naive/ruler16k_naive_hs0.5_pcs1024_ns40/hf_prefill.log" ORACLE_TOPK_HEAVY_SIZE=0.5 NUM_SAMPLES=40 RULER_TASKS="" python test_sparse_oracle_ruler16k.py > "/home/nvidia/shubham/sparse/new_sparse/sparse-attention-hub/output_ruler16k_naive/ruler16k_naive_hs0.5_pcs1024_ns40/log.txt" 2>&1
