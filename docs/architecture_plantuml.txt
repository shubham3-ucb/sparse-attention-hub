@startuml
skinparam style strictuml

' === Sparse Attention ===
abstract SparseAttention {
  + custom_attention(): Tuple[Tensor, Optional[Tensor]]
  + pre_attention_hook_generator(): void
}
abstract EfficientAttention extends SparseAttention {
  + custom_attention(): Tuple[Tensor, Optional[Tensor]]
}
abstract ResearchAttention extends SparseAttention {
  + masks: Sequence(ResearchMasker)
  + custom_attention(): Tuple[Tensor, Optional[Tensor]]
}
class DoubleSparsity extends EfficientAttention {
  + custom_attention(): Tuple[Tensor, Optional[Tensor]]
}
class HashAttention extends EfficientAttention {
  + custom_attention(): Tuple[Tensor, Optional[Tensor]]
}

abstract ResearchMasker {
  + add_mask(keys, queries, values, previous_attention_mask, prev_num, prev_den, List[ResearchMasker])
  + get_attention_numerator(keys, queries, values, mask)
  + get_attention_denominator(keys, queries, values, mask)
}

abstract SamplingMasker extends ResearchMasker
abstract FixedMasker extends ResearchMasker

abstract topKMasker extends FixedMasker
abstract topPMasker extends FixedMasker
class RLocalMasker extends FixedMasker
class RCausalMasker extends FixedMasker
class RSinkMasker extends FixedMasker

class RPQCache extends topKMaster
class ROracletopK extends topKMasker
class RHashAttention extends topKMasker
class RDoubleSparsity extends topKMasker


class RRandomSampling extends SamplingMasker
class RMagicPig extends SamplingMakser


abstract SparseAttentionGen {
  + get_custom_attention_function()
  + __call__()
}
class SparseAttentionHF extends SparseAttentionGen {
}
class SparseAttentionMetadata {
  + layer_wise_state: Dict
  + global_state_: Dict
}

' === Model Hub ===
abstract ModelHub {
  + api_token: String
  + addPreAttentionHooks(model, hook_generator, hook_name)
  + removePreAttentionHooks(model, hook_name)
  + replaceAttentionInterface(model, attention_interface_callable, attention_interface_name)
  + revertAttentionInterface(model)
}
class ModelHubHF extends ModelHub{
  + field: type
  + method(type): type
}

' == Pipeline ==
abstract Pipeline {

}
class PipelineHF extends Pipeline{
 
}

class SparseAttentionServer {
  + port: String
  + execute(ModelHub, SparseAttentionStrategy)
}



' === Benchmark  ===

abstract Benchmark {
  + name
  + subsets
  + create_hugging_face_dataset()
  + run_benchmark()
  + calculate_metrics
}

class LongBench extends Benchmark
class Loogle extends Benchmark
class InfBench extends Benchmark

class BenchmarkExecutor {
  + field: type
  + evaluate(Benchmark)
  + result_storage: ResultStorage
}

class ResultStorage {
  + storage_path: String
  + store(List[String]): String
}

' === MetricLogger ==

class MicroMetricLogger <<singleton>> {
  + available_metrics: List[MicroMetric]
  + metrics_to_log: List[MicroMetric]
  + path_to_log
  + register_metric()
  + should_log_metric()
  + log(location, metric, value)
}

abstract MicroMetric {
  + name
  + compute(*args, **kwargs)
}

class TopkRecall extends MicroMetric{
  + name
  + compute(*args, **kwargs)
}

class LocalError extends MicroMetric {
  + name
  + compute(*args, **kwargs)
}

class SampleVariance extends MicroMetric {
  + name
  + compute(*args, **kwargs)
}


' === Plotting ===
class PlotGenerator {
  + storage_path: String
  + generate_plot(Granularity): String
  - generate_plot_1(Granularity): String
  - generate_plot_2(Granularity): String
}

enum Granularity {
  PER_TOKEN
  PER_HEAD
  PER_LAYER
}

' === Tester ===
class Tester {
  + execute_all_tests()
  + execute_unit_tests()
  + execute_integration_tests()
}

' ==  dependencies ==
SparseAttention *-- SparseAttentionMetaData
SparseAttentionGen o-- SparseAttention
ResearchAttention o-- ResearchMasker
SparseAttentionServer o-- Pipeline
BenchmarkExecutor o-- Benchmark
BenchmarkExecutor *-- ResultStorage
MicroMetricLogger o-- MicroMetric
PlotGenerator o-- Granularity



@enduml
