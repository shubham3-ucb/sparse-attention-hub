{
  "model_name": "meta-llama/Llama-3.2-1B-Instruct",
  "generation_kwargs": {
    "max_new_tokens": 8
  },
  "request_kwargs": {
    "max_context_length": 2000,
    "truncate_from_middle": true
  }
}